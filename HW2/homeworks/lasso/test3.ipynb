{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import problem\n",
    "\n",
    "\n",
    "def random_data_generator(n, d, k, mean, variance) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Generates random data sets for X and y based on the dimensions and noise\n",
    "\n",
    "    Args:\n",
    "        n: number of rows of X\n",
    "        d: number of features of X\n",
    "        k: number of relevant features of X\n",
    "        mean: mean of the noise term\n",
    "        variance: variance of the noise term\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: Tuple with 2 entries. First represents input data X, second represents response y\n",
    "\n",
    "    \"\"\"\n",
    "    w = np.zeros((d, 1))\n",
    "\n",
    "    for j in range(k) :\n",
    "        w[j] = (j + 1) / k\n",
    "\n",
    "    X = np.random.normal(size=(n, d))\n",
    "    noise = np.random.normal(scale=np.sqrt(variance), size=(n,))\n",
    "\n",
    "    y = np.reshape(np.dot(w.T, X.T) + noise.T, (n,))\n",
    "\n",
    "    return (X, y)\n",
    "\n",
    "\n",
    "@problem.tag(\"hw2-A\")\n",
    "def step(\n",
    "    X: np.ndarray, y: np.ndarray, weight: np.ndarray, bias: float, _lambda: float, eta: float\n",
    ") -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Single step in ISTA algorithm.\n",
    "    It should update every entry in weight, and then return an updated version of weight along with calculated bias on input weight!\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): An (n x d) matrix, with n observations each with d features.\n",
    "        y (np.ndarray): An (n, ) array, with n observations of targets.\n",
    "        weight (np.ndarray): An (d,) array. Weight returned from the step before.\n",
    "        bias (float): Bias returned from the step before.\n",
    "        _lambda (float): Regularization constant. Determines when weight is updated to 0, and when to other values.\n",
    "        eta (float): Step-size. Determines how far the ISTA iteration moves for each step.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, float]: Tuple with 2 entries. First represents updated weight vector, second represents bias.\n",
    "\n",
    "    \"\"\"\n",
    "    # weight = weight.reshape(len(weight), 1)\n",
    "    # weight_ = np.zeros(weight.shape)\n",
    "    n = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "\n",
    "    if weight is None:\n",
    "        w = np.zeros((d,))\n",
    "    else:\n",
    "        w = weight\n",
    "\n",
    "    bias_ = bias - 2 * eta * np.sum(X.dot(w) + bias - y)\n",
    "\n",
    "    #c = np.zeros((d,))\n",
    "    c = w.copy()\n",
    "    for k in range(d):\n",
    "        #c[k] = c[k] - 2 * eta * np.dot( y - (bias_ + np.dot(w.T, X.T) - w[k] * X[:, k]),X.T[k])\n",
    "\n",
    "        #c[k] = c[k] - 2 * eta * np.dot((np.dot( w.T, X.T)+ bias_ - y),X.T[1])\n",
    "        # print (f' non zeroes in input weight - {np.count_nonzero(w)}')\n",
    "\n",
    "        c[k] = w[k] - 2 * eta * np.dot((np.dot( w.T, X.T) - y),X.T[k])\n",
    "\n",
    "        if c[k] < -2 * eta * _lambda:\n",
    "            w[k] = c[k] + 2 * eta * _lambda\n",
    "        elif c[k] > 2 * eta * _lambda:\n",
    "            w[k] = c[k] - 2 * eta * _lambda\n",
    "        else:\n",
    "            w[k] = 0\n",
    "\n",
    "    return (w, bias_)\n",
    "\n",
    "    # raise NotImplementedError(\"Your Code Goes Here\")\n",
    "\n",
    "\n",
    "@problem.tag(\"hw2-A\")\n",
    "def loss(\n",
    "    X: np.ndarray, y: np.ndarray, weight: np.ndarray, bias: float, _lambda: float\n",
    ") -> float:\n",
    "    \"\"\"L-1 (Lasso) regularized MSE loss.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): An (n x d) matrix, with n observations each with d features.\n",
    "        y (np.ndarray): An (n, ) array, with n observations of targets.\n",
    "        weight (np.ndarray): An (d,) array. Currently predicted weights.\n",
    "        bias (float): Currently predicted bias.\n",
    "        _lambda (float): Regularization constant. Should be used along with L1 norm of weight.\n",
    "\n",
    "    Returns:\n",
    "        float: value of the loss function\n",
    "    \"\"\"\n",
    "\n",
    "    return np.square(np.subtract(y, np.dot(X, weight))).sum() + _lambda * np.linalg.norm(weight, 1)\n",
    "\n",
    "    # raise NotImplementedError(\"Your Code Goes Here\")\n",
    "\n",
    "\n",
    "@problem.tag(\"hw2-A\", start_line=5)\n",
    "def train(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    _lambda: float = 0.01,\n",
    "    eta: float = 0.001,\n",
    "    convergence_delta: float = 1e-4,\n",
    "    start_weight: np.ndarray = None,\n",
    "    start_bias: float = None\n",
    ") -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Trains a model and returns predicted weight and bias.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): An (n x d) matrix, with n observations each with d features.\n",
    "        y (np.ndarray): An (n, ) array, with n observations of targets.\n",
    "        _lambda (float): Regularization constant. Should be used for both step and loss.\n",
    "        eta (float): Step size.\n",
    "        convergence_delta (float, optional): Defines when to stop training algorithm.\n",
    "            The smaller the value the longer algorithm will train.\n",
    "            Defaults to 1e-4.\n",
    "        start_weight (np.ndarray, optional): Weight for hot-starting model.\n",
    "            If None, defaults to array of zeros. Defaults to None.\n",
    "            It can be useful when testing for multiple values of lambda.\n",
    "        start_bias (np.ndarray, optional): Bias for hot-starting model.\n",
    "            If None, defaults to zero. Defaults to None.\n",
    "            It can be useful when testing for multiple values of lambda.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, float]: A tuple with first item being array of shape (d,) representing predicted weights,\n",
    "            and second item being a float representing the bias.\n",
    "\n",
    "    Note:\n",
    "        - You will have to keep an old copy of weights for convergence criterion function.\n",
    "            Please use `np.copy(...)` function, since numpy might sometimes copy by reference,\n",
    "            instead of by value leading to bugs.\n",
    "        - You might wonder why do we also return bias here, if we don't need it for this problem.\n",
    "            There are two reasons for it:\n",
    "                - Model is fully specified only with bias and weight.\n",
    "                    Otherwise you would not be able to make predictions.\n",
    "                    Training function that does not return a fully usable model is just weird.\n",
    "                - You will use bias in next problem.\n",
    "    \"\"\"\n",
    "    if start_weight is None:\n",
    "        start_weight = np.zeros(X.shape[1])\n",
    "        start_bias = 0\n",
    "    old_w: Optional[np.ndarray] = None\n",
    "    old_b: Optional[float] = None\n",
    "\n",
    "    while not convergence_criterion(start_weight, old_w, start_bias, old_b, convergence_delta):\n",
    "        old_w = start_weight.copy()\n",
    "        old_b = start_bias\n",
    "        start_weight, start_bias = step(X, y, start_weight, start_bias, _lambda, eta)\n",
    "        old_b = start_bias\n",
    "\n",
    "    return (start_weight, start_bias)\n",
    "\n",
    "    # raise NotImplementedError(\"Your Code Goes Here\")\n",
    "\n",
    "\n",
    "@problem.tag(\"hw2-A\")\n",
    "def convergence_criterion(\n",
    "    weight: np.ndarray, old_w: np.ndarray, bias: float, old_b: float, convergence_delta: float\n",
    ") -> bool:\n",
    "    \"\"\"Function determining whether weight has converged or not.\n",
    "    It should calculate the maximum absolute change between weight and old_w vector, and compare it to convergence delta.\n",
    "\n",
    "    Args:\n",
    "        weight (np.ndarray): Weight from current iteration of coordinate gradient descent.\n",
    "        old_w (np.ndarray): Weight from previous iteration of coordinate gradient descent.\n",
    "        convergence_delta (float): Aggressiveness of the check.\n",
    "\n",
    "    Returns:\n",
    "        bool: False, if weight has not converged yet. True otherwise.\n",
    "    \"\"\"\n",
    "    if (weight is None or old_w is None):\n",
    "        return False\n",
    "    else:\n",
    "        return (np.any(abs((np.subtract(weight, old_w))) > convergence_delta))\n",
    "    # raise NotImplementedError(\"Your Code Goes Here\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1478.0866971385647\n",
      "[1478.0866971385647]\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "d = 1000\n",
    "k = 100\n",
    "mean = 0\n",
    "var = 1\n",
    "# Step 1 - Create the random set of data\n",
    "X, y = random_data_generator(n, d, k, mean, var)\n",
    "\n",
    "# Step 2 - Standardize X and save values\n",
    "X_std = (X - np.mean(X, axis=0)) / (np.std(X, axis=0))\n",
    "fit_mean = np.mean(X, axis=0)\n",
    "fit_std = np.std(X, axis=0)\n",
    "\n",
    "#print(X_std, y)\n",
    "\n",
    "\n",
    "\n",
    "# Step 3 - Calculate lambda_max, the initial step\n",
    "_lambda = 2 * np.max(np.abs(np.dot(y.T - np.mean(y), X_std)))\n",
    "_lambda_step = 2\n",
    "eta = 0.00001\n",
    "convergence_delta = 0.0001\n",
    "\n",
    "print(_lambda)\n",
    "\n",
    "\n",
    "# Step 4 - Solve multiple lasso problems using decreasing lambda\n",
    "current_lamba = _lambda\n",
    "lamba_vals = [_lambda]\n",
    "\n",
    "W_all = np.zeros((d, 1))\n",
    "print(lamba_vals)\n",
    "\n",
    "print(W_all.shape)\n",
    "\n",
    "#np.savetxt(\"X.csv\", X, delimiter=\",\")\n",
    "#np.savetxt(\"y.csv\", y, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "weights are [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "bias = 0.001317923545023096 \n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(W_all))\n",
    "Wa,ba = step(X_std, y, None, 0, _lambda, eta)\n",
    "\n",
    "print(f'weights are {Wa} \\n' )\n",
    "print(f'bias = {ba} \\n' )\n",
    "\n",
    "print(np.count_nonzero(Wa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a shape = (1, 500), b shape = (500,), c shape = (1, 500)\n",
      " X.T Shape (500,)\n",
      " X shape (1000,)\n",
      " Xk shape (500,)\n",
      " X.T Shape (500,)\n",
      " a shape = (1, 500), b shape = (500,), c shape = (1, 500), d shape = (1,) , e shape = (1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nc = np.zeros((d,))\\nfor k in range(d):\\n    c[k] = 2 * eta * np.dot(X[:, k], y - (bias_ + np.dot(w.T, X.T) - w[k] * X[:, k]))\\n\\n    if c[k] < -2 * eta * _lambda:\\n        w[k] = c[k] + 2 * eta * _lambda\\n    elif c[k] > -2 * eta * _lambda:\\n        w[k] = c[k] - 2 * eta * _lambda\\n    else:\\n        w[k] = 0\\n'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_std\n",
    "bias = 0\n",
    "weight = W_all\n",
    "bias_ = bias - 2 * eta * np.sum(X.dot(weight) + bias - y)\n",
    "\n",
    "n = X.shape[0]\n",
    "d = X.shape[1]\n",
    "\n",
    "if weight is None:\n",
    "    w = np.zeros((d,))\n",
    "else:\n",
    "    w = weight\n",
    "\n",
    "a = np.dot(w.T, X.T)\n",
    "#print (a)\n",
    "\n",
    "b=  w[1] * X[:, 1]\n",
    "#print(f'b is {b}')\n",
    "\n",
    "c = y - (bias_ + np.dot(w.T, X.T) - w[k] * X[:, k])\n",
    "\n",
    "print (f' a shape = {a.shape}, b shape = {b.shape}, c shape = {c.shape}')\n",
    "\n",
    "\n",
    "print (f' X.T Shape {X.T[1].shape}')\n",
    "\n",
    "\n",
    "print (f' X shape {X[1].shape}')\n",
    "\n",
    "Xk = X.T[1]\n",
    "#Xk.reshape(len(Xk),1)\n",
    "\n",
    "#Xk = Xk.reshape(-1)\n",
    "Xk = np.squeeze(Xk)\n",
    "\n",
    "print (f' Xk shape {Xk.shape}')\n",
    "\n",
    "print (f' X.T Shape {X.T[k].shape}')\n",
    "\n",
    "d = np.dot( y - (bias_ + np.dot(w.T, X.T) - w[k] * X[:, k]),Xk.T)\n",
    "#d = Xk.dot(y - (bias_ + np.dot(w.T, X.T) - w[k] * X[:, k]))\n",
    "\n",
    "#print (f' a shape = {a.shape}, b shape = {b.shape}, c shape = {c.shape}, d shape = {d.shape} ')\n",
    "\n",
    "#e = np.dot( (np.dot(X.T[1], w.T)+ bias_ - y),X.T[1] )\n",
    "#e =  np.dot(X.T[1],(np.dot(X, w)+ bias_ - y))\n",
    "e = np.dot((np.dot( w.T, X.T)+ bias_ - y),X.T[1])\n",
    "\n",
    "print (f' a shape = {a.shape}, b shape = {b.shape}, c shape = {c.shape}, d shape = {d.shape} , e shape = {e.shape}')\n",
    "\n",
    "'''\n",
    "c = np.zeros((d,))\n",
    "for k in range(d):\n",
    "    c[k] = 2 * eta * np.dot(X[:, k], y - (bias_ + np.dot(w.T, X.T) - w[k] * X[:, k]))\n",
    "\n",
    "    if c[k] < -2 * eta * _lambda:\n",
    "        w[k] = c[k] + 2 * eta * _lambda\n",
    "    elif c[k] > -2 * eta * _lambda:\n",
    "        w[k] = c[k] - 2 * eta * _lambda\n",
    "    else:\n",
    "        w[k] = 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'initial non zeroes = {np.count_nonzero(W_all[:, -1])}')\n",
    "while np.count_nonzero(W_all[:, -1]) < 900:\n",
    "    print(\"Current lambda = \", current_lamba)\n",
    "\n",
    "    (w_new, bias) = train(X_std, y, current_lamba, eta, convergence_delta)\n",
    "    print(f'W new is {w_new} \\n')\n",
    "\n",
    "    W_all = np.concatenate((W_all, np.expand_dims(w_new, axis=1)), axis=1)\n",
    "    print(f'non zeroes = {np.count_nonzero(W_all[:, -1])}')\n",
    "    current_lamba = current_lamba / _lambda_step\n",
    "    lamba_vals.append(current_lamba)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse446",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
